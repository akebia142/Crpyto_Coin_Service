# -*- coding: utf-8 -*-
"""boston_housing_examp02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QnwRfn0aKOckc64-hm2xhtNwrMUfFked
"""

#1.데이터 수집
import tensorflow as tf

(x_train, y_train), (x_test, y_test) =tf.keras.datasets.boston_housing.load_data(
    path='boston_housing.npz', test_split=0.2, seed=113
)
print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)
print(y_train.std())

#2 데이터의 유형이나 관련필드를 분석( 결측치나 이상치 확인)및 분류
 #CRIM     per capita crime rate by town
 #ZN       proportion of residential land zoned for lots over 25,000 sq.ft.
 #INDUS    proportion of non-retail business acres per town
 #CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
 #NOX      nitric oxides concentration (parts per 10 million)
 #RM       average number of rooms per dwelling
 #AGE      proportion of owner-occupied units built prior to 1940
 #DIS      weighted distances to five Boston employment centres
 #RAD      index of accessibility to radial highways
 #TAX      full-value property-tax rate per $10,000
 #PTRATIO  pupil-teacher ratio by town
 #B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
 #LSTAT    % lower status of the population
# y값 MEDV     Median value of owner-occupied homes in $1000's

for ix,d in enumerate(x_train[0]):
  print(ix+1,"타입:" ,type(d))
data_label=["범죄율","토지비율","비소매업면적","찰스강 변수(0or1)","산화질소농도","평균방수","고택비율","고용거리","고속접근","재산세율","교학생비율","흑인비율","하위계층비율"]
for ix,d in enumerate(x_train[0]):
  print(f"{ix}. {data_label[ix]} : {d}",end="| ")
print(f" {d}")

import matplotlib.pyplot as plt
for ix in range(len(x_train[0])):
  plt.subplot(4,4,ix+1)
  plt.scatter(y_train,x_train[:,ix],label=data_label[ix],s=1)
  plt.title(ix)
plt.show()

# 데이터 크기
for ix in range(len(x_train[0])):
  print(ix,".")
  print(x_train[:,ix].max(),end=": ")
  print(x_train[:,ix].min(),end=": ")
  print(x_train[:,ix].std(),end=": ")
  print(x_train[:,ix].mean(),end=": ")
  print()

# 3번과 4번 필드를 제외한 데이터 정규화 스케일링
except_datas=[3,4]
norm_mean=[]
norm_std=[]
for ix in range(len(x_train[0])):
  if ix in except_datas:
    norm_mean.append(0)
    norm_std.append(1)
    continue
  norm_mean.append(x_train[:,ix].mean())
  norm_std.append(x_train[:,ix].std())
print(norm_mean)
print(norm_std)
def normal_data(target_data):
  for ix in range(len(target_data[0])):
      if ix in except_datas:
        continue
      #데이터를 표준 정규분포로 스케일링
      target_data[:,ix]=(target_data[:,ix]-norm_mean[ix])/norm_std[ix]
  return target_data

x_train = normal_data(x_train)
x_test = normal_data(x_test)
print(x_train[:3])
print(x_test[:3])
print(x_train[:,0].std())
print(x_train[:,0].mean())
print(x_train[:,-1].std())
print(x_train[:,-1].mean())

#4. 모델 만들기
from tensorflow.keras import Input, Sequential
from tensorflow.keras.layers import Dense, Dropout
import numpy as np
print(x_train.shape)

import random
random.seed(123)
np.random.seed(123)
tf.random.set_seed(123)
model = Sequential()
model.add(Input((13,)))
model.add(Dense(256,activation="relu"))
#res = model(np.array([x_train[0]]))
#print(len(res[0]))
#print(res)
model.add(Dropout(0.4))
model.add(Dense(64,activation="relu"))
model.add(Dropout(0.3))
model.add(Dense(16,activation="relu"))
model.add(Dense(1))
model.compile(loss="MSE", optimizer="SGD",metrics=['MAE'])

# 역전파에서도 아주 작은값을 계속 전해줄수 있게 하는게 relu함수

y_mean=y_train.mean()
y_std = y_train.std()
y_train = (y_train-y_mean)/y_std
y_test = (y_test-y_mean)/y_std
fhist = model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=500)

plt.plot(fhist.history["loss"],label="mse")
plt.plot(fhist.history["MAE"],label="mae")
plt.legend()
plt.show()

y_pred=model.predict(x_test)
plt.plot(y_test,y_test,label="y_True")
plt.scatter(y_pred,y_pred,label="y_Pred")
plt.legend()
plt.show()

print(y_pred.shape)
print(y_test.shape)
y_pred = y_pred.reshape(-1)
print(y_pred.shape)

# t = (y - mean) /std >  y=t*std+mean
#y_mean
#y_std
y_pred = y_pred*y_std+y_mean
y_test = y_test*y_std+y_mean
print(y_pred[1])
print(y_test[1])
print((1-(y_pred[1]/y_test[1]))*100)
rate = 1-y_pred/y_test
print(rate[:5])
rate = np.absolute(rate)
err_rate_mean = rate[:5].mean()
print(f"현재 모델의 전체 오차 평균 백분율은 {err_rate_mean:.2%}")